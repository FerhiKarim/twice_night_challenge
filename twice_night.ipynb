{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from shapely import wkt\n",
        "import geopandas as gpd\n",
        "\n",
        "# Load datasets\n",
        "admin_data = pd.read_csv('/content/sample_data/admin_merged.csv')\n",
        "soil_data = pd.read_csv('/content/sample_data/soil_merged.csv')\n",
        "spatial_data = pd.read_csv('/content/sample_data/spatial_merged.csv')\n",
        "\n",
        "# Handle missing data\n",
        "admin_data = admin_data.dropna(subset=['SURFACE', 'PERIMETRE'])\n",
        "soil_data = soil_data.dropna(subset=['SURFACE', 'PERIMETRE'])\n",
        "spatial_data = spatial_data.dropna(subset=['SURFACE', 'PERIMETRE'])\n",
        "\n",
        "# Combine datasets\n",
        "combined_data = pd.merge(admin_data, soil_data, on=['SURFACE', 'PERIMETRE'], how='outer')\n",
        "combined_data = pd.merge(combined_data, spatial_data, on=['SURFACE', 'PERIMETRE'], how='outer')\n",
        "\n",
        "# Remove columns with empty values or '?????' columns\n",
        "combined_data = combined_data.loc[:, (combined_data != '?????').any(axis=0)]  # Remove columns with '?????'\n",
        "combined_data = combined_data.dropna(axis=1, how='all')  # Remove completely empty columns\n",
        "\n",
        "# Handle categorical columns by applying one-hot encoding\n",
        "categorical_columns = ['ADM_GOV', 'CLASS_FIN', 'NOM', 'TEXTURE_x', 'COULEUR_x', 'ROCHE_ME_x']\n",
        "combined_data = pd.get_dummies(combined_data, columns=categorical_columns, drop_first=True)\n",
        "\n",
        "# Handle remaining object columns that are not encoded\n",
        "for col in combined_data.select_dtypes(include=['object']).columns:\n",
        "    print(f\"Encoding column: {col}\")\n",
        "    le = LabelEncoder()\n",
        "    combined_data[col] = le.fit_transform(combined_data[col])\n",
        "\n",
        "# Handle missing values\n",
        "combined_data = combined_data.fillna(0)\n",
        "\n",
        "# Convert soil geometry to GeoDataFrame\n",
        "if 'geometry' in soil_data.columns:\n",
        "    soil_data['geometry'] = soil_data['geometry'].apply(wkt.loads)  # Convert WKT to geometry\n",
        "    soil_gdf = gpd.GeoDataFrame(soil_data, geometry='geometry')  # Create GeoDataFrame\n",
        "    soil_gdf['centroid_x'] = soil_gdf.geometry.centroid.x  # Extract centroid X coordinate\n",
        "    soil_gdf['centroid_y'] = soil_gdf.geometry.centroid.y  # Extract centroid Y coordinate\n",
        "    soil_gdf['area'] = soil_gdf.geometry.area  # Calculate area\n",
        "else:\n",
        "    print(\"Warning: 'geometry' column is missing in soil data. Skipping spatial feature extraction.\")\n",
        "\n",
        "# Convert spatial geometry to GeoDataFrame\n",
        "if 'geometry' in spatial_data.columns:\n",
        "    spatial_data['geometry'] = spatial_data['geometry'].apply(wkt.loads)  # Convert WKT to geometry\n",
        "    spatial_gdf = gpd.GeoDataFrame(spatial_data, geometry='geometry')  # Create GeoDataFrame\n",
        "    spatial_gdf['centroid_x'] = spatial_gdf.geometry.centroid.x  # Extract centroid X coordinate\n",
        "    spatial_gdf['centroid_y'] = spatial_gdf.geometry.centroid.y  # Extract centroid Y coordinate\n",
        "    spatial_gdf['area'] = spatial_gdf.geometry.area  # Calculate area\n",
        "else:\n",
        "    print(\"Warning: 'geometry' column is missing in spatial data. Skipping spatial feature extraction.\")\n",
        "\n",
        "# Combine spatial features with the rest of the data\n",
        "combined_data = pd.merge(combined_data, soil_gdf[['SURFACE', 'PERIMETRE', 'centroid_x', 'centroid_y', 'area']], on=['SURFACE', 'PERIMETRE'], how='left')\n",
        "combined_data = pd.merge(combined_data, spatial_gdf[['SURFACE', 'PERIMETRE', 'centroid_x', 'centroid_y', 'area']], on=['SURFACE', 'PERIMETRE'], how='left')\n",
        "\n",
        "# Normalize numerical features\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Check if 'area' column exists before normalizing\n",
        "numerical_features = ['SURFACE', 'PERIMETRE']\n",
        "if 'area' in combined_data.columns:\n",
        "    numerical_features.append('area')\n",
        "\n",
        "# Normalize features\n",
        "combined_data[numerical_features] = scaler.fit_transform(combined_data[numerical_features])\n",
        "\n",
        "# Define the target variable (suitability for olive trees)\n",
        "def is_suitable_for_olive_trees(row):\n",
        "    # Criteria based on domain knowledge\n",
        "    if row['SURFACE'] > 50 and row['CLASS_FIN'] == 'Agricultural':\n",
        "        if row['TEXTURE_x'] in ['sandy-loam', 'loam', 'clay-loam']:\n",
        "            if row['SALURE_x'] < 10 and row['PROFOND_x'] > 50 and row['CHARG_CA_x'] > 5:\n",
        "                if 10 < row['ACT_EAU_x'] < 70:\n",
        "                    return 1  # Suitable land for olive trees\n",
        "    return 0  # Not suitable land for olive trees\n",
        "\n",
        "# Apply the rule to the dataset to create the target variable\n",
        "combined_data['suitable_for_olive_trees'] = combined_data.apply(is_suitable_for_olive_trees, axis=1)\n",
        "\n",
        "# Features (X) and target (Y)\n",
        "columns_to_drop = ['suitable_for_olive_trees']\n",
        "if 'geometry' in combined_data.columns:\n",
        "    columns_to_drop.append('geometry')\n",
        "\n",
        "X = combined_data.drop(columns=columns_to_drop)\n",
        "y = combined_data['suitable_for_olive_trees']\n",
        "\n",
        "# Check class balance in the target variable\n",
        "print(\"Class distribution of 'suitable_for_olive_trees':\")\n",
        "print(y.value_counts())\n",
        "\n",
        "# Optionally, apply class balancing techniques (e.g., SMOTE, undersampling) if needed\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model = RandomForestClassifier(random_state=42, max_depth=10, min_samples_split=10, min_samples_leaf=5)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy Score:\", accuracy)\n",
        "\n",
        "# Cross-validation scores\n",
        "cv_scores = cross_val_score(model, X, y, cv=5)\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "print(\"Mean cross-validation score:\", cv_scores.mean())\n",
        "\n",
        "# Optionally, print feature importance to understand which features matter most\n",
        "importances = model.feature_importances_\n",
        "features = X.columns\n",
        "\n",
        "feature_importance_df = pd.DataFrame({'Feature': features, 'Importance': importances})\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"Feature Importance:\")\n",
        "print(feature_importance_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVYDff-vr9uq",
        "outputId": "13f7a284-69c6-48df-94db-cab51b798864"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding column: ADM_DEL\n",
            "Encoding column: ?????\n",
            "Encoding column: texture _C\n",
            "Encoding column: texture _N\n",
            "Encoding column: COULEUR_Cl\n",
            "Encoding column: nom_couleu\n",
            "Encoding column: geometry_x\n",
            "Encoding column: geometry_y\n",
            "Class distribution of 'suitable_for_olive_trees':\n",
            "suitable_for_olive_trees\n",
            "0    865072\n",
            "Name: count, dtype: int64\n",
            "Accuracy Score: 1.0\n",
            "Cross-validation scores: [1. 1. 1. 1. 1.]\n",
            "Mean cross-validation score: 1.0\n",
            "Feature Importance:\n",
            "              Feature  Importance\n",
            "0             ADM_IDE         0.0\n",
            "64    COULEUR_x_705.0         0.0\n",
            "74   ROCHE_ME_x_107.0         0.0\n",
            "73   ROCHE_ME_x_105.0         0.0\n",
            "72   ROCHE_ME_x_103.0         0.0\n",
            "..                ...         ...\n",
            "31               TYPE         0.0\n",
            "30                 ID         0.0\n",
            "29        index_right         0.0\n",
            "28         geometry_y         0.0\n",
            "101            area_y         0.0\n",
            "\n",
            "[102 rows x 2 columns]\n"
          ]
        }
      ]
    }
  ]
}